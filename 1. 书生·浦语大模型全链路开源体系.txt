1. 书生·浦语大模型全链路开源体系

·大模型成为发展通用人工智能的重要途径
专用模型（2006-2021）：针对特定任务，一个模型解决一个问题，如 ImageNet 竞赛、AlphaGo
通用大模型：一个模型应对多种任务、多种模态，如 ChatGPT

·书生·浦语 2.0（InternLM2）的体系
面向不同的使用需求，每个规格包含三个模型版本
7B（为轻量级的研究和应用提供了一个轻便但性能不俗的模型）           InternLM2-Base：高质量和具有很强可塑性的模型基座，是模型进行深度领域适配的高质量起点
                                                                                              >   InternLM2：在Base基础上，在多个能力方向进行了强化，在评测中成绩优异，同时保持了很好的通用语言能力，
                                                                                                    是我们推荐的在大部分应用中考虑选用的优秀基座
20B（模型的综合性能更为强劲，可有效支持更加复杂的使用场景）      InternLM2-Chat：在Base基础上，经过SFT和RLHF，面向对话交互进行了优化，具有很好的指令遵循、共情聊天和调用工具等的能力

*SFT（Supervised Fine-Tuning）：监督微调指在源数据集上预训练一个神经网络模型，即源模型。然后创建一个新的神经网络模型，即目标模型。目标模型复制了源模型上除了输出层以外的所有模型设计及其参数。这些模型参数包含了从源数据集上学习到的知识，并且这些知识同样适用于目标数据集。由于源模型的输出层与源数据集的标签紧密相关，因此在目标模型中不予采用。在微调时，为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。在目标数据集上训练目标模型时，应从头训练到输出层，其余层的参数则都基于源模型的参数微调得出。
步骤：预训练→微调→评估
*RLHF（Reinforcement Learning from Human Feedback）：人类反馈强化学习指将人类的反馈纳入训练过程，为机器提供了一种自然的、人性化的互动学习过程。

·回归语言建模的本质
使用新一代数据清洗过滤技术
多维度数据价值评估：基于文本质量、信息质量、信息密度等维度对数据价值进行综合评估与提升
高质量语料驱动的数据富集：利用高质量语料的特征从物理世界、互联网以及语料库中进一步富集更多类似资料
有针对性的数据补齐：针对性补充语料，重点加强世界知识、数理、代码等核心能力

InternLM2 的loss分布曲线在初代 InternLM 的基础上向左移动，证明其具有更加强大的语言建模能力。

·书生·浦语 2.0（InternLM2）的主要亮点
超长上下文、综合性能全面提升、优秀的对话和创作体验、工具调用能力整体升级、突出的数理能力和使用的数据分析功能

·从模型到应用典型流程
模型选型（评测）→业务场景是否复杂→是→算力足够吗→是→续训/全参数微调      
                                                                                 否→部分参数微调           >   是否需要环境交互→是→构建智能体      
                                                                                                                                                      否                          >   模型测评→模型部署
                                                        否→                                                

·书生·浦语全链条开源开放体系
数据（书生·万卷）：2TB 数据，涵盖多种模态与任务
预训练（InternLM-Train）：并行训练，极致优化，速度达到3600 tokens/sec/gpu
微调（XTuner）：支持全参数微调，支持 LoRA 等低成本微调
部署（LMDeploy）：全链路部署，性能领先，每秒生成2000+ tokens
评测（OpenCompass）：全方位评测，性能可复现100套评测集，50万道题目
应用（Lagent & AgentLego）：支持多种智能体，支持代码解释器等多种工具

·全链条开源开放体系 | 开放高质量语料数据
书生·万卷 1.0：符合主流中国价值观的中文语料
数据构成：文本数据、图像-文本数据集、视频数据
书生·万卷 CC：安全、信息密度更高的英文语料
三大优势：时间跨度长、来源丰富多样、安全密度高

·全链条开源开放体系 | 预训练
训练算法           预训练                                 微调
训练优势           高性能 Transformer 计算库   多种并行策略
通信/计算调度   梯度累积算法选择                  通信/计算重叠
显存管理           优化器状态 梯度                    参数

*梯度累积（Gradient Accumulation）：在深度学习训练的时候，经常会出现内存不够用的问题。而且，数据的batch size大小也受制于GPU内存。batch size大小会影响模型的最终准确性以及训练过程的性能。在GPU内存不变的情况下，模型越大，就意味着batch size只能缩小。而梯度累积可以解决这个问题。梯度累积可以将数据样本按batch拆分成几个小batch，然后按顺序进行计算。它只计算神经网络模型参数的梯度，并不及时更新网络模型参数，同时累积通过计算得到的梯度信息，最终统一使用累积的梯度对参数进行更新。

高可扩展：支持8 卡到千卡训练，千卡加速效率达92%
极致性能优化：Hybrid Zero 独特技术+极致优化，加速50%
兼容主流：无缝接入 HuggingFace 等技术生态，支持各类轻量化技术
开箱即用：支持多种规格语言模型，修改配置即可训练

·全链条开源开放体系 | 微调
大语言模型的下游应用中，增量续训和有监督微调是常用的两种方式。
增量续训：
使用场景：让基座模型学习到一些新知识，如某个垂类领域知识
训练数据：文章、书籍、代码等
有监督微调：
使用场景：让模型学会理解各种指令进行对话，或者注入少量领域知识
训练数据：高质量的对话、问答数据

高效微调框架 XTuner
适配多种生态：多种微调算法、适配多种开源生态、自动优化加速
适配多种硬件：训练方案覆盖 NVIDIA 20 系以上所有显卡、最低只需8 GB显存即可微调7 B模型

·CompassKit: 大模型评测全栈工具链
OpenCompass 核心代码库功能全面升级：数据污染检查、更丰富的模型推理接入、长文本能力评测、中英文双语主观评测

·全链条开源开放体系 | 部署
LMDeploy 提供大模型在GPU上部署的全流程解决方案，包括模型轻量化、推理和服务。
接口：Python、gRPC、RESTful
轻量化：4bit权重、8bit k/v
推理引擎：turbomind、pytorch
服务：openai-server、gradio、triton inference server

*k/v存储：一种常用的数据存储方式，其中k表示键（key），v表示值（value）

高效推理引擎、完备易用的工具链、支持交互式推理

·全链条开源开放体系 | 智能体

*智能体（Agent）：一个具有自治能力、自适应性的软件、硬件或其他实体。它是以云为基础，以AI为核心，被构建出的一个立体感知、全域协同、精准判断、持续进化、开放的智能系统。它的目标是认识和模拟人类的智能行为，可以被看作一个能够持续地、自主地发挥作用，并与环境进行交互的计算实体。

轻量级智能体框架 Lagent：支持多种类型的智能体能力、灵活支持多种大语言模型、支持丰富的工具
